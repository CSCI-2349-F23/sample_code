{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 9.2: n-grams and collocations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here's some code to get us started imports, creating a decent stop list, and then a function for reading in and tokenizing. I've pre-processed the Gutenberg books to remove all the intro and legal language at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# improving stop word list\n",
    "# get stop word list\n",
    "stoplist = stopwords.words('english')\n",
    "stoplist.extend([\".\", \",\", \"?\", \"could\", \"would\", \"“\", \"”\", \"’\", \";\", \"!\",\"much\", \"like\", \"one\", \"many\", \"though\", \"without\", \"upon\"])\n",
    "\n",
    "\n",
    "# function for reading in, tokenizing\n",
    "def readdata(filename):\n",
    "    # open the file, read it in, replace newlines with space\n",
    "    f = open(filename, encoding=\"utf=8\")\n",
    "    fulltext = f.read()\n",
    "    alltext = re.sub(\"\\n\", \" \", fulltext)\n",
    "\n",
    "    # call nltk.word_tokenize\n",
    "    alltokens = nltk.word_tokenize(alltext)    \n",
    "    return alltokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Okay, let's do great expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((',', 'and'), 3715), (('.', '“'), 1362), (('”', '“'), 1249), (('’', 's'), 1151), ((',', '”'), 1118), ((',', 'I'), 1025), (('”', 'said'), 933), ((',', '“'), 895), (('?', '”'), 892), (('of', 'the'), 831)]\n"
     ]
    }
   ],
   "source": [
    "greattokens = readdata(\"greatexpectations.txt\")\n",
    "\n",
    "# get bigrams|\n",
    "bigrams = nltk.ngrams(greattokens, 2)\n",
    "bigramlist = list(bigrams)\n",
    "\n",
    "# print out most frequent bigrams\n",
    "bigramfreq = nltk.FreqDist(bigramlist)\n",
    "print(bigramfreq.most_common(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsurprisingly, the most frequent bigrams all involve punctuation and stop words! Let's try to filter those out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('Miss', 'Havisham'), 299)\n",
      "(('Mr.', 'Jaggers'), 213)\n",
      "(('said', 'Joe'), 121)\n",
      "(('said', 'Mr.'), 117)\n",
      "(('Mr.', 'Wopsle'), 110)\n",
      "(('Mr.', 'Pumblechook'), 89)\n",
      "(('Mr.', 'Pip'), 66)\n",
      "(('said', 'Wemmick'), 63)\n",
      "(('Mrs.', 'Joe'), 60)\n",
      "(('Mrs.', 'Pocket'), 53)\n",
      "(('dear', 'boy'), 52)\n",
      "(('Mr.', 'Pocket'), 51)\n",
      "(('said', 'Herbert'), 51)\n",
      "(('old', 'chap'), 37)\n",
      "(('said', 'Estella'), 37)\n",
      "(('Mr.', 'Wemmick'), 34)\n",
      "(('Miss', 'Skiffins'), 31)\n",
      "(('young', 'man'), 26)\n",
      "(('young', 'gentleman'), 25)\n",
      "(('said', 'Biddy'), 25)\n"
     ]
    }
   ],
   "source": [
    "# print out most frequent bigrams where neither word is a stop word\n",
    "for b in bigramfreq.most_common(1000):\n",
    "    if b[0][0].lower() not in stoplist and b[0][1].lower() not in stoplist:\n",
    "        print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That tells us a lot more about Great Expectations! Let's put all that in a function so we can call it with other books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's put that bigram frequency code in a function\n",
    "\n",
    "def get_bigrams(tokenlist):\n",
    "    bigrams = nltk.ngrams(tokenlist, 2)\n",
    "    bigramlist = list(bigrams)\n",
    "\n",
    "    # print out most frequent bigrams\n",
    "    bigramfreq = nltk.FreqDist(bigramlist)\n",
    "    print(bigramfreq.most_common(10))\n",
    "\n",
    "    # print out most frequent bigrams where neither word is a stop word\n",
    "    for b in bigramfreq.most_common(1000):\n",
    "        if b[0][0].lower() not in stoplist and b[0][1].lower() not in stoplist:\n",
    "            print(b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now on to Walden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((',', 'and'), 1850), (('of', 'the'), 850), (('in', 'the'), 641), (('.', 'I'), 431), (('.', 'The'), 360), (('to', 'the'), 343), ((',', 'or'), 331), (('and', 'the'), 313), ((',', 'as'), 307), (('’', 's'), 302)]\n",
      "(('New', 'England'), 19)\n",
      "(('Walden', 'Pond'), 14)\n",
      "(('*', '*'), 13)\n",
      "(('every', 'day'), 12)\n"
     ]
    }
   ],
   "source": [
    "# Walden\n",
    "# You can change the argument to most_common in the code above to see more bigrams from Walden.\n",
    "\n",
    "waldentokens = readdata(\"walden.txt\")\n",
    "get_bigrams(waldentokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And here's a really different one: Romeo and Juliet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((',', 'and'), 181), (('Rom', '.'), 163), (('.', 'I'), 159), ((',', 'I'), 123), (('Jul', '.'), 117), (('.', 'Rom'), 114), (('Nurse', '.'), 102), ((',', 'And'), 97), (('.', 'O'), 85), (('.', 'Jul'), 73)]\n",
      "(('thou', 'art'), 24)\n",
      "(('art', 'thou'), 19)\n",
      "(('Romeo', \"'s\"), 19)\n",
      "(('thou', 'wilt'), 17)\n",
      "(('thou', 'hast'), 16)\n",
      "(('[', 'Exit'), 14)\n",
      "((\"'s\", 'dead'), 13)\n",
      "(('Enter', 'Romeo'), 12)\n",
      "(('Capulet', \"'s\"), 12)\n",
      "(('Friar', 'Laurence'), 11)\n",
      "(('Enter', 'Juliet'), 10)\n",
      "(('good', 'night'), 10)\n",
      "(('love', \"'s\"), 9)\n",
      "(('County', 'Paris'), 9)\n",
      "(('lady', \"'s\"), 9)\n",
      "(('Enter', 'Friar'), 9)\n",
      "(('Tybalt', \"'s\"), 9)\n",
      "((\"'s\", 'death'), 9)\n",
      "(('[', 'aside'), 8)\n",
      "(('thy', 'love'), 8)\n",
      "((']', 'Rom'), 8)\n",
      "(('Juliet', \"'s\"), 7)\n",
      "(('pray', 'thee'), 7)\n",
      "(('[', 'Exeunt'), 7)\n",
      "(('men', \"'s\"), 7)\n",
      "(('[', 'Laurence'), 7)\n",
      "(('Laurence', ']'), 7)\n",
      "(('Enter', 'Nurse'), 7)\n",
      "(('kill', \"'d\"), 7)\n",
      "(('tell', 'thee'), 6)\n",
      "((\"'s\", 'house'), 6)\n",
      "((\"'s\", 'cell'), 6)\n",
      "(('Chief', 'Watch'), 6)\n",
      "(('Friar', 'John'), 5)\n",
      "(('Enter', 'Benvolio'), 5)\n",
      "(('Exeunt', '['), 5)\n",
      "(('lovers', \"'\"), 5)\n",
      "(('Scene', 'II'), 5)\n",
      "((\"'ll\", 'tell'), 5)\n",
      "(('Scene', 'III'), 5)\n",
      "(('Wilt', 'thou'), 5)\n",
      "((']', 'Jul'), 5)\n",
      "(('Good', 'night'), 5)\n",
      "((\"'s\", 'orchard'), 5)\n",
      "(('aside', ']'), 5)\n",
      "(('thou', 'dost'), 5)\n",
      "(('thousand', 'times'), 5)\n",
      "(('Laurence', \"'s\"), 5)\n",
      "(('man', \"'s\"), 5)\n",
      "(('Laurence', \"'\"), 5)\n",
      "((\"'\", 'cell'), 5)\n",
      "(('Friar', '['), 5)\n",
      "(('thou', 'shalt'), 5)\n",
      "(('Prince', \"'s\"), 5)\n",
      "(('Mercutio', \"'s\"), 5)\n",
      "(('thou', 'hadst'), 4)\n",
      "(('Enter', 'Old'), 4)\n",
      "(('Thou', 'shalt'), 4)\n",
      "(('let', \"'s\"), 4)\n",
      "(('th', \"'\"), 4)\n",
      "(('Enter', 'Capulet'), 4)\n",
      "(('make', 'thee'), 4)\n",
      "((\"'ll\", 'go'), 4)\n"
     ]
    }
   ],
   "source": [
    "# Romeo and Juliet\n",
    "romeotokens = readdata(\"romeo.txt\")\n",
    "get_bigrams(romeotokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Collocations\n",
    "\n",
    "There are ways of finding characteristic two- (or three-) word sequences that don't involve just filtering out stop words. Typically, we use statistical metrics to identify bigrams where one or both of the words is not particularly frequent by itself but when they do occur, they tend to occur together. These are called **collocations**, and nltk has a nice module for finding them.\n",
    "\n",
    "Below, we use the statistical measure called pointwise mutual information (PMI). There are other options in `bigram_measures` such as chi square and likelihood ratios that you can experiment with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great Expectations\n",
      "[('Accoucheur', 'Policeman'), ('Arabian', 'Nights'), ('Assurance', 'shares'), ('Bear—bear', 'witness.'), ('Been', 'bolting'), ('Bosworth', 'Field'), ('Botany', 'Bay'), ('Chelsea', 'Reach'), ('Cock', 'Robin'), ('Come—to', 'play.')]\n",
      "Walden\n",
      "[('.........', '7.50'), ('.............................', '2.25'), ('..............................', '3.12½'), ('...............................', '0.40'), ('0.01', 'Transportation'), ('0.14', 'Latch'), ('0.15', 'Nails'), ('0.25', 'Dried'), ('0.40', 'Turnip'), ('0.54', 'Ploughing')]\n",
      "Juliet\n",
      "[(\"'It\", 'lightens'), (\"'Signior\", 'Martino'), (\"'When\", 'griping'), ('-the', 'Clown'), ('AND', 'JULIET'), ('Alike', 'bewitched'), ('Alla', 'stoccata'), ('Ancient', 'damnation'), ('Brief', 'sounds'), ('Dramatis', 'Personae')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.collocations import *\n",
    "\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "\n",
    "print(\"Great Expectations\")\n",
    "finder = BigramCollocationFinder.from_words(greattokens)\n",
    "print(finder.nbest(bigram_measures.pmi, 10))\n",
    "\n",
    "print(\"Walden\")\n",
    "finder = BigramCollocationFinder.from_words(waldentokens)\n",
    "print(finder.nbest(bigram_measures.pmi, 10))\n",
    "\n",
    "print(\"Juliet\")\n",
    "finder = BigramCollocationFinder.from_words(romeotokens)\n",
    "print(finder.nbest(bigram_measures.pmi, 10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving collocations\n",
    "Those collocations are weird and unhelpful for the most part. Because of the way PMI works, the collocations with the highest scores are often themselves very infrequent. We can filter out the ones that occur only once or twice and find other interesting collocations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great Expectations\n",
      "Habraham Latharuth\n",
      "T GO\n",
      "filed asunder\n",
      "Copper Rope-walk\n",
      "Bartholomew Close\n",
      "Cousin Raymond\n",
      "scented soap\n",
      "Covent Garden\n",
      "Green Copper\n",
      "aged parent\n",
      "\n",
      "Walden\n",
      "CIVIL DISOBEDIENCE\n",
      "DUTY OF\n",
      "Loch Fyne\n",
      "OF CIVIL\n",
      "_terra firma_\n",
      "ON THE\n",
      "THE DUTY\n",
      "nineteenth century\n",
      "Green Mountains\n",
      "Fair Haven\n",
      "\n",
      "Juliet\n",
      "plague o\n",
      "thousand times\n",
      "Chief Watch\n",
      "Make haste\n",
      "They fight\n",
      "honest gentleman\n",
      "Thursday next\n",
      "said 'Ay\n",
      "silver sound\n",
      "Scene II\n"
     ]
    }
   ],
   "source": [
    "print(\"Great Expectations\")\n",
    "finder = BigramCollocationFinder.from_words(greattokens)\n",
    "finder.apply_freq_filter(3)\n",
    "for c in finder.nbest(bigram_measures.pmi, 10):\n",
    "    print(\" \".join(c))\n",
    "\n",
    "\n",
    "print(\"\\nWalden\")\n",
    "finder = BigramCollocationFinder.from_words(waldentokens)\n",
    "finder.apply_freq_filter(3)\n",
    "for c in finder.nbest(bigram_measures.pmi, 10):\n",
    "    print(\" \".join(c))\n",
    "\n",
    "print(\"\\nJuliet\")\n",
    "finder = BigramCollocationFinder.from_words(romeotokens)\n",
    "finder.apply_freq_filter(3)\n",
    "for c in finder.nbest(bigram_measures.pmi, 10):\n",
    "    print(\" \".join(c))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collocations: nearby but not necessarily adjacent words\n",
    "\n",
    "You can also think of collocations as two words that occur frequently in the same general area but not always exactly next to each other.  `BigramCollocationFinder` allows you to look within a \"window\" to find words that occur near each other frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('fee', 'simple'), (\"'Heart\", 'ease'), ('lick', 'fingers'), ('ACT', 'I.'), ('Saint', 'Church'), ('hare', 'hoar'), ('plague', 'o'), ('bite', 'thumb'), ('through', 'veins'), ('Alack', 'alack')]\n",
      "[('DON', 'GO'), ('Habraham', 'Latharuth'), ('twig', 'blade'), ('beats', 'cringes'), ('flint', 'steel'), ('backwards', 'forwards'), ('DON', 'T'), ('T', 'GO'), ('filed', 'asunder'), ('Copper', 'Rope-walk')]\n",
      "[('hoo', 'hoorer'), ('CIVIL', 'DISOBEDIENCE'), ('DUTY', 'CIVIL'), ('DUTY', 'DISOBEDIENCE'), ('DUTY', 'OF'), ('Loch', 'Fyne'), ('OF', 'CIVIL'), ('OF', 'DISOBEDIENCE'), ('ON', 'CIVIL'), ('ON', 'DUTY')]\n"
     ]
    }
   ],
   "source": [
    "finder = BigramCollocationFinder.from_words(romeotokens, window_size=5)\n",
    "finder.apply_freq_filter(3)\n",
    "print(finder.nbest(bigram_measures.pmi, 10))\n",
    "\n",
    "finder = BigramCollocationFinder.from_words(greattokens, window_size=5)\n",
    "finder.apply_freq_filter(3)\n",
    "print(finder.nbest(bigram_measures.pmi, 10))\n",
    "\n",
    "finder = BigramCollocationFinder.from_words(waldentokens, window_size=5)\n",
    "finder.apply_freq_filter(3)\n",
    "print(finder.nbest(bigram_measures.pmi, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see words that co-occur not necessarily next to each other: \n",
    "\n",
    "* Saint Church, e.g., \"the church of Saint So-and-so\"\n",
    "* backwards forwards, e.g., \"backwards and forwards\"\n",
    "* through veins, e.g., \"through my veins\"\n",
    "  \n",
    "\n",
    "### Using other association metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CIVIL', 'DISOBEDIENCE'), ('DUTY', 'OF'), ('Loch', 'Fyne'), ('OF', 'CIVIL'), ('_terra', 'firma_'), ('ON', 'THE'), ('THE', 'DUTY'), ('nineteenth', 'century'), ('Green', 'Mountains'), ('Fair', 'Haven')]\n",
      "[(',', 'and'), ('’', 's'), ('.', 'The'), ('.', 'It'), ('of', 'the'), ('in', 'the'), ('.', 'I'), (';', 'but'), ('to', 'be'), ('It', 'is')]\n",
      "[('CIVIL', 'DISOBEDIENCE'), ('DUTY', 'OF'), ('Fair', 'Haven'), ('Loch', 'Fyne'), ('OF', 'CIVIL'), ('_terra', 'firma_'), ('’', 's'), ('ON', 'THE'), ('THE', 'DUTY'), ('&', 'c.')]\n"
     ]
    }
   ],
   "source": [
    "finder = BigramCollocationFinder.from_words(waldentokens)\n",
    "finder.apply_freq_filter(3)\n",
    "print(finder.nbest(bigram_measures.pmi, 10))\n",
    "print(finder.nbest(bigram_measures.likelihood_ratio, 10))\n",
    "print(finder.nbest(bigram_measures.chi_sq, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: You can do all this for trigrams, too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
